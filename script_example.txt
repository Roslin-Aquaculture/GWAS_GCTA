#!/bin/bash

##### SET UP names of files, directories and chromosomes numbers --> this needs to be modify to fit your files names, chromsome number and trait name
## In this example script it correspond to the example files on sex determinism in Turbot available in this repository

#Name of the .ped and .map files , name of the phenotype covariates and fixed effect files eg ${MyData}.pheno ${MyData}.covar ${MyData}.qcovar
MyData=Turbot
# The namne of the final genotype file post QC will be ${MyData}_final.bed .bim and .fam

#Name of the trait
MyTrait=SEX

#Number of chromosomes in the dataset
chr_number=22


##### Thresholds for quality controls on SNP and Individuals 
# Genotype missing call rate = SNPs with a missing call rate over this value will be removed from the dataset 
Geno_CallRate=0.05 
# Individual call rate = Individuals with a genotype call rate below this value will be removed from the dataset
IID_CallRate=0.1
# Hardy W Equilibrium = will be removed from the dataset
HVE_pval=0.000001 
# Minor Allele Frequency = SNPs with a MAF below this value will be removed from the dataset
MAF_thr=0.05



####################################### START of the ANALYSIS

# We transform from PED format to BINARY format (.bed, .bim, .fam)

plink --ped ${MyData}.ped --map ${MyData}.map --chr-set ${chr_number} --make-bed --out ${MyData}


# We use a plink command line --genome to get the IBD values of each pair of individuals in order to identify duplicated samples, if any, and remove them
plink --bfile ${MyData} --chr-set ${chr_number} --genome --out ${Mydata}

# gwak comman lines to detect the duplicated samples (IBD > 0.9), create a file with Family_ID and Individual_ID to filter them out of the dataset
gawk -v IBD_thr=0.90 ' NR > 1 { if ($10 > IBD_thr) { print $1" " $2 " " $3 " " $4 }}' ${MyData}.genome > duplicated_ID.txt
gawk '{print $1 " " $2}' duplicated_ID.txt > ID_to_remove.txt
gawk '{print $3 " " $4}' duplicated_ID.txt >> ID_to_remove.txt

#Those three lines of awk are used to create a file that contain the Family_ID and the fish_ID of duplicated samples to be removed from the dataset using the following plink line:
plink --bfile ${MyData} --remove ID_to_remove.txt --make-bed --out noduplic${MyData}


#################	Quality control
# This command is used to perform all other quality controls on the dataset:
plink --bfile noduplic${MyData} --chr-set ${chr_number} --geno ${Geno_CallRate} --mind ${IID_CallRate} --hwe ${HVE_pval} --maf ${MAF_thr} --nonfounders --make-bed --out ${MyData}_Final


############### GWAS
#GRM
gcta64 --bfile ${MyData}_Final --autosome-num ${chr_number} --make-grm --out GRM_${MyData} --thread-num 10

#AI-REML with a fixed effect in the model (--qcovar)
gcta64 --reml --grm GRM_${MyData} --pheno ${MyData}.pheno --qcovar ${MyData}.qcovar --out reml_${MyTrait}

#MLMA with a fixed effect in the model(--qcovar)
gcta64 --mlma --bfile ${MyData}_Final --autosome-num ${chr_number} --grm GRM_${MyData} --pheno ${MyData}.pheno --qcovar ${MyData}.qcovar --out gwas_${MyData}_${MyTrait} > gwas_mlma.log

#MLMA-LOCO with a fixed effect in the model(--qcovar)
gcta64 --mlma-loco --bfile ${MyData}_Final --autosome-num ${chr_number} --grm GRM_${MyData} --pheno ${MyData}.pheno --qcovar ${MyData}.qcovar --out gwas_${MyData}_${MyTrait} > gwas_mlma-loco.log
